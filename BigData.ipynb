{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BigData.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRInq5gOmSuC",
        "colab_type": "text"
      },
      "source": [
        "# NYC fare prediction\n",
        "\n",
        "[This notebook](TBD) shows my approach for predicting the fare amount for a taxi ride in NYC when given the pickup and dropoff locations of the passangers regarding the [New York City Taxi Fare Prediction Challange]( https://www.kaggle.com/c/new-york-city-taxi-fare-prediction).\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "This notebook is seperated into different sections, relating to the common data science workflow (except the hypothesis and data collection where already done).\n",
        "\n",
        "\n",
        "0.   Previous Commits\n",
        "1.   Setup and Check Infrastructure\n",
        "2.   Having a first look at the Data (EDA)\n",
        "3.   Data Cleaning (Feature Engineering)\n",
        "4.   Linear Regression\n",
        "5.   Ridge Regression\n",
        "6.   Model ...\n",
        "7.   Evaulation and Discussion\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVXtwXAHLD44",
        "colab_type": "text"
      },
      "source": [
        "# 0. Previous Commits - Comparison of different Models:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fEoMZTsLSd7",
        "colab_type": "text"
      },
      "source": [
        "Predictions are done when using the whole data set\n",
        "\n",
        "### Linear Regression\n",
        "\n",
        "**Commit 1 (Baseline) Score: 5.67093**\n",
        "- 5.67093\n",
        " \n",
        "\n",
        "### Ridge Regression\n",
        "\n",
        "**Commit 2 Score: 12.54277**\n",
        "\n",
        "params_ridge\n",
        "  - alpha = loguniform(1e-5, 1e0)\n",
        "  - solver = ['eig', 'cd']\n",
        "  - n_iter = 100\n",
        "  - cv = 5\n",
        "  - verbose = 0\n",
        "  - n_jobs = 1\n",
        "\n",
        "ridge_params\n",
        "  - alpha = 0.240960447726532\n",
        "  - fit_intercept = True\n",
        "  - normalize = False\n",
        "  - solver = 'eig'\n",
        "\n",
        "RMSE for Ridge_rmse Regression is  -7.212150573730469\n",
        "\n",
        "\n",
        "### K-Nearest Neighbor \n",
        "**Commit 3 Score: 4.86790**\n",
        "  - n_neighbors = 4\n",
        "  - data_size = 5.5 Mio rows (1 %)\n",
        "\n",
        "### Random Forest \n",
        "**Commit 4 Score: 5.95518**\n",
        "  - n_estimators=10\n",
        "  - n_jobs=-1\n",
        "  - data_size = 1 Mio. rows\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_g3Zj-nHUeR",
        "colab_type": "text"
      },
      "source": [
        "# 1. Setup and Check Infrastructure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKBQtZzV2zNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Switch from Kaggle to Colab easily\n",
        "environment='Colab'\n",
        "\n",
        "## when True only 50.000 rows are used for debugging purpose. Set to False when doing real training\n",
        "debug_mode=True \n",
        "\n",
        "## choose how many rows of the training data sample you would like to use (only works when debug_mode=False ), max is 55423480\n",
        "rows_datasample=5542348"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF1XfHZiw0-e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "62870c46-725b-477c-ddcd-7b071c6a5e81"
      },
      "source": [
        "if environment == 'Kaggle':\n",
        "  env_submission_path='./'\n",
        "  env_path='../input/new-york-city-taxi-fare-prediction/'\n",
        "  print('The environment and paths were successfully setup for Kaggle')\n",
        "elif environment == 'Colab':\n",
        "  env_submission_path='/content/drive/My Drive/Colab Notebooks/'\n",
        "  env_path='/content/drive/My Drive/Colab Notebooks/'\n",
        "\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "  print('The environment and paths were successfully setup for Colab')\n",
        "\n",
        "else:\n",
        "  print('Something went wrong here, please choose one of the options for path completion: Kaggle or Colab (or implement your own thing)')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "The environment and paths were successfully setup for Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ri5Sq2eHPp7",
        "colab_type": "text"
      },
      "source": [
        "Check for GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix7egkMuVbLC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e197c4cd-87ef-487e-9066-ae1b8f531a52"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Sep 22 14:37:35 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P8    35W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY8-qcVuVguX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e225d50f-bf74-4358-f16b-ce5298bf2969"
      },
      "source": [
        "if environment == 'Kaggle':\n",
        "  import sys\n",
        "  !cp ../input/rapids/rapids.0.14.0 /opt/conda/envs/rapids.tar.gz\n",
        "  !cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n",
        "  sys.path = [\"/opt/conda/envs/rapids/lib/python3.7/site-packages\"] + sys.path\n",
        "  sys.path = [\"/opt/conda/envs/rapids/lib/python3.7\"] + sys.path\n",
        "  sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path \n",
        "  !cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/\n",
        "  print('You are all set for the kaggle rapids environment')\n",
        "\n",
        "elif environment == 'Colab':\n",
        "  # Install RAPIDS and Dask_ml\n",
        "  !pip install dask_ml\n",
        "  !pip install dask_cuda\n",
        "  !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "  !bash rapidsai-csp-utils/colab/rapids-colab.sh stable\n",
        "\n",
        "  import sys, os\n",
        "  dist_package_index = sys.path.index('/usr/local/lib/python3.6/dist-packages')\n",
        "  sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.6/site-packages'] + sys.path[dist_package_index:]\n",
        "  sys.path\n",
        "  exec(open('rapidsai-csp-utils/colab/update_modules.py').read(), globals())\n",
        "  print('You are all set for the colab rapids environment')\n",
        "\n",
        "else:\n",
        "  print('Something went wrong here, please choose one of the options for path completion: Kaggle or Colab (or implement your own thing). If Kaggle failed please make sure you added the RAPIDS file on Kaggle to your Input!')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dask_ml in /usr/local/lib/python3.6/site-packages (1.6.0)\n",
            "Requirement already satisfied: multipledispatch>=0.4.9 in /usr/local/lib/python3.6/site-packages (from dask_ml) (0.6.0)\n",
            "Requirement already satisfied: distributed>=2.4.0 in /usr/local/lib/python3.6/site-packages (from dask_ml) (2.27.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/site-packages (from dask_ml) (0.50.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/site-packages (from dask_ml) (1.4.1)\n",
            "Requirement already satisfied: dask[array,dataframe]>=2.4.0 in /usr/local/lib/python3.6/site-packages (from dask_ml) (2.27.0)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.6/site-packages (from dask_ml) (0.25.3)\n",
            "Requirement already satisfied: dask-glm>=0.2.0 in /usr/local/lib/python3.6/site-packages (from dask_ml) (0.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/site-packages (from dask_ml) (20.4)\n",
            "Requirement already satisfied: scikit-learn>=0.23 in /usr/local/lib/python3.6/site-packages (from dask_ml) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.6/site-packages (from dask_ml) (1.19.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from multipledispatch>=0.4.9->dask_ml) (1.15.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (1.6.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (1.0.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (7.1.2)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (49.6.0.post20200917)\n",
            "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (6.0.4)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (5.7.2)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (0.10.0)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (1.6.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (2.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (5.3.1)\n",
            "Requirement already satisfied: contextvars; python_version < \"3.7\" in /usr/local/lib/python3.6/site-packages (from distributed>=2.4.0->dask_ml) (2.4)\n",
            "Requirement already satisfied: llvmlite<0.34,>=0.33.0.dev0 in /usr/local/lib/python3.6/site-packages (from numba->dask_ml) (0.33.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0; extra == \"dataframe\" in /usr/local/lib/python3.6/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (0.8.2)\n",
            "Requirement already satisfied: partd>=0.3.10; extra == \"dataframe\" in /usr/local/lib/python3.6/site-packages (from dask[array,dataframe]>=2.4.0->dask_ml) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/site-packages (from pandas>=0.23.4->dask_ml) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/site-packages (from pandas>=0.23.4->dask_ml) (2020.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/site-packages (from packaging->dask_ml) (2.4.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.23->dask_ml) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/site-packages (from scikit-learn>=0.23->dask_ml) (0.16.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.6/site-packages (from zict>=0.1.3->distributed>=2.4.0->dask_ml) (1.0.1)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/site-packages (from contextvars; python_version < \"3.7\"->distributed>=2.4.0->dask_ml) (0.14)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.6/site-packages (from partd>=0.3.10; extra == \"dataframe\"->dask[array,dataframe]>=2.4.0->dask_ml) (0.2.0)\n",
            "Requirement already satisfied: dask_cuda in /usr/local/lib/python3.6/site-packages (0.15.0)\n",
            "Requirement already satisfied: pynvml>=8.0.3 in /usr/local/lib/python3.6/site-packages (from dask_cuda) (8.0.4)\n",
            "Requirement already satisfied: numba>=0.40.1 in /usr/local/lib/python3.6/site-packages (from dask_cuda) (0.50.1)\n",
            "Requirement already satisfied: distributed>=2.18.0 in /usr/local/lib/python3.6/site-packages (from dask_cuda) (2.27.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/site-packages (from dask_cuda) (1.19.1)\n",
            "Requirement already satisfied: dask>=2.9.0 in /usr/local/lib/python3.6/site-packages (from dask_cuda) (2.27.0)\n",
            "Requirement already satisfied: llvmlite<0.34,>=0.33.0.dev0 in /usr/local/lib/python3.6/site-packages (from numba>=0.40.1->dask_cuda) (0.33.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/site-packages (from numba>=0.40.1->dask_cuda) (49.6.0.post20200917)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.6/site-packages (from distributed>=2.18.0->dask_cuda) (1.0.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.6/site-packages (from distributed>=2.18.0->dask_cuda) (5.7.2)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.6/site-packages (from distributed>=2.18.0->dask_cuda) (2.0.0)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.6/site-packages (from distributed>=2.18.0->dask_cuda) (7.1.2)\n",
            "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.6/site-packages (from distributed>=2.18.0->dask_cuda) (6.0.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/site-packages (from distributed>=2.18.0->dask_cuda) (5.3.1)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.6/site-packages (from distributed>=2.18.0->dask_cuda) (1.6.0)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.6/site-packages (from distributed>=2.18.0->dask_cuda) (0.10.0)\n",
            "Requirement already satisfied: contextvars; python_version < \"3.7\" in /usr/local/lib/python3.6/site-packages (from distributed>=2.18.0->dask_cuda) (2.4)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.6/site-packages (from distributed>=2.18.0->dask_cuda) (1.6.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.6/site-packages (from distributed>=2.18.0->dask_cuda) (2.2.2)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.6/site-packages (from zict>=0.1.3->distributed>=2.18.0->dask_cuda) (1.0.1)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/site-packages (from contextvars; python_version < \"3.7\"->distributed>=2.18.0->dask_cuda) (0.14)\n",
            "fatal: destination path 'rapidsai-csp-utils' already exists and is not an empty directory.\n",
            "PLEASE READ\n",
            "********************************************************************************************************\n",
            "Changes:\n",
            "1. IMPORTANT CHANGES: RAPIDS on Colab will be pegged to 0.14 Stable until further notice.\n",
            "2. Default stable version is now 0.14.  Nightly will redirect to 0.14.\n",
            "3. You can now declare your RAPIDSAI version as a CLI option and skip the user prompts (ex: '0.14' or '0.15', between 0.13 to 0.14, without the quotes): \n",
            "        \"!bash rapidsai-csp-utils/colab/rapids-colab.sh <version/label>\"\n",
            "        Examples: '!bash rapidsai-csp-utils/colab/rapids-colab.sh 0.14', or '!bash rapidsai-csp-utils/colab/rapids-colab.sh stable', or '!bash rapidsai-csp-utils/colab/rapids-colab.sh s'\n",
            "                  '!bash rapidsai-csp-utils/colab/rapids-colab.sh 0.15, or '!bash rapidsai-csp-utils/colab/rapids-colab.sh nightly', or '!bash rapidsai-csp-utils/colab/rapids-colab.sh n'\n",
            "Enjoy using RAPIDS!  If you have any issues with or suggestions for RAPIDSAI on Colab, please create a bug request on https://github.com/rapidsai/rapidsai-csp-utils/issues/new.  Thanks!\n",
            "Starting to prep Colab for install RAPIDS Version 0.14 stable\n",
            "Checking for GPU type:\n",
            "Traceback (most recent call last):\n",
            "  File \"rapidsai-csp-utils/colab/env-check.py\", line 25, in <module>\n",
            "    \"\"\")\n",
            "Exception: \n",
            "    Unfortunately Colab didn't give you a T4, P4, or P100 GPU.\n",
            "    \n",
            "    Make sure you've configured Colab to request a GPU instance type.\n",
            "    \n",
            "    If you get a different GPU, try Runtime -> Reset all runtimes...\n",
            "  \n",
            "\n",
            "************************************************\n",
            "Your Google Colab instance has RAPIDS installed!\n",
            "************************************************\n",
            "***********************************************************************\n",
            "Let us check on those pyarrow and cffi versions...\n",
            "***********************************************************************\n",
            "\n",
            "You're don't have pyarrow.\n",
            "unloaded cffi 1.14.2\n",
            "loaded cffi 1.11.5\n",
            "You are all set for the colab rapids environment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTWeyn2qYyl5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "792b9225-ba2e-4933-a68e-629a736e5f74"
      },
      "source": [
        "import nvstrings\n",
        "import numpy as np\n",
        "import cudf, cuml\n",
        "import dask_cudf\n",
        "import io, requests\n",
        "import math\n",
        "import gc\n",
        "import cupy as cp\n",
        "import pandas as pd\n",
        "\n",
        "#Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns \n",
        "\n",
        "#Learning\n",
        "from cuml.preprocessing.model_selection import train_test_split\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Linear Models https://github.com/rapidsai/cuml/tree/branch-0.13/notebooks\n",
        "from cuml.linear_model import LinearRegression # Linear\n",
        "from cuml.linear_model import LogisticRegression # Logisitc\n",
        "from cuml.linear_model import ElasticNet # Elastic\n",
        "from cuml.linear_model import Ridge # Ridge\n",
        "from cuml.linear_model import Lasso # Lasso\n",
        "from cuml.linear_model import MBSGDRegressor as cumlMBSGDRegressor # Mini Batch SGD Regressor\n",
        "\n",
        "from cuml.solvers import SGD as cumlSGD # Stochastic Gradient Descent\n",
        "from cuml.ensemble import RandomForestRegressor as cuRF # Random Forest\n",
        "from cuml.dask.ensemble import RandomForestClassifier as cumlDaskRF # RandomForest\n",
        "\n",
        "from cuml.neighbors import KNeighborsRegressor as cumlKNR # Nearest Neighbours\n",
        "from cuml.svm import SVC # Support Vector Machines\n",
        "\n",
        "from cuml import ForestInference\n",
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from cuml.metrics.regression import r2_score\n",
        "from cuml.metrics.accuracy import accuracy_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score as sk_acc\n",
        "from sklearn.utils.fixes import loguniform"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: nvstrings will be removed in 0.15. Please use equivalent from libcudf\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/site-packages/cudf/utils/gpu_utils.py:58: UserWarning: You will need a GPU with NVIDIA Pascal™ or newer architecture\n",
            "Detected GPU 0: Tesla K80\n",
            "Detected Compute Capability: 3.7\n",
            "  + str(minor_version)\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw7sbM1_ukTi",
        "colab_type": "text"
      },
      "source": [
        "If you find yourself running these notebooks on Colab as well as on Kaggle you might find this placeholder thing helpful. Only thing to touch ist the environment you are running on (Kaggle or Colab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysZh0eaaHZT4",
        "colab_type": "text"
      },
      "source": [
        "# 2. First look at the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9AE7Djfw8uN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cudf.set_allocator(\"managed\")\n",
        "dtype = {'fare_amount': 'float32',\n",
        "              'pickup_datetime':'str',\n",
        "              'pickup_longitude': 'float32',\n",
        "              'pickup_latitude': 'float32',\n",
        "              'dropoff_longitude': 'float32',\n",
        "              'dropoff_latitude': 'float32',\n",
        "              'passenger_count': 'int8'}\n",
        "\n",
        "usecols = list(dtype.keys())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlQ0urKVpLfB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "9483163e-9d33-46ec-b1a2-84f7ccdf5add"
      },
      "source": [
        "%%time\n",
        "# use a subset with 50.000 rows, max is nrows = 55423480\n",
        "\n",
        "if debug_mode != True:\n",
        "  ## using 1% (or how much you like)\n",
        "  nrwos=rows_datasample\n",
        "else:\n",
        "  ## using a very small sample just for testing\n",
        "  nrows = 50000\n",
        "\n",
        "test = cudf.read_csv(env_path+'test.csv', usecols=usecols, dtype=dtype)\n",
        "train = cudf.read_csv(env_path+'train.csv', nrows=nrows, usecols=usecols, dtype=dtype)\n",
        "submission = cudf.read_csv(env_path+'sample_submission.csv', usecols=usecols, dtype=dtype)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-88d2d397d711>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"# use a subset with 50.000 rows, max is nrows = 55423480\\n\\nif debug_mode != True:\\n  ## using 1% (or how much you like)\\n  nrwos=rows_datasample\\nelse:\\n  ## using a very small sample just for testing\\n  nrows = 50000\\n\\ntest = cudf.read_csv(env_path+'test.csv', usecols=usecols, dtype=dtype)\\ntrain = cudf.read_csv(env_path+'train.csv', nrows=nrows, usecols=usecols, dtype=dtype)\\nsubmission = cudf.read_csv(env_path+'sample_submission.csv', usecols=usecols, dtype=dtype)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'debug_mode' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eij2FPF2vuTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5631wMlv9FY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_WXW01AHlC4",
        "colab_type": "text"
      },
      "source": [
        "# 3. Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ka9ezhECWv0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Drop Nan Values\n",
        "train.nans_to_nulls()\n",
        "train = train.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3ZMKboWCGD1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e783afc2-a122-409d-c52c-75ed91e1e15c"
      },
      "source": [
        "#Checking shape of the data\n",
        "print(\"Train: \" + str(train.shape))\n",
        "print(\"Test: \" + str(test.shape))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fffe86c03a1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Checking shape of the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Test: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xko9RCA4v_Hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Changing the data format of pickup_datetime and adding additional information about pickup time\n",
        "train['pickup_datetime'] = train['pickup_datetime'].astype('datetime64[ns]')\n",
        "\n",
        "train[\"hour\"] = train.pickup_datetime.dt.hour\n",
        "train[\"weekday\"] = train.pickup_datetime.dt.weekday\n",
        "train[\"month\"] = train.pickup_datetime.dt.month\n",
        "train[\"year\"] = train.pickup_datetime.dt.year\n",
        "\n",
        "\n",
        "test['pickup_datetime'] = test['pickup_datetime'].astype('datetime64[ns]')\n",
        "\n",
        "test[\"hour\"] = test.pickup_datetime.dt.hour\n",
        "test[\"weekday\"] = test.pickup_datetime.dt.weekday\n",
        "test[\"month\"] = test.pickup_datetime.dt.month\n",
        "test[\"year\"] = test.pickup_datetime.dt.year"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iUREXQ5CEzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculate trip distance in miles\n",
        "def distance(lat1, lon1, lat2, lon2):\n",
        "    p = 0.017453292519943295 # Pi/180\n",
        "    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n",
        "    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymO-WYlaCGS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['distance'] = distance(train['pickup_latitude'], train['pickup_longitude'], train['dropoff_latitude'], train['dropoff_longitude'] )\n",
        "test['distance'] = distance(test['pickup_latitude'], test['pickup_longitude'], test['dropoff_latitude'], test['dropoff_longitude'] )\n",
        "train['distance'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZliSrMSwyJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check if everything worked\n",
        "train.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FpQJz9Zxxd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFYnmMIiDfyJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Ararage fare amount: \" + str(train['fare_amount'].mean()))\n",
        "print(\"Standard deviation fare amount: \" + str(train['fare_amount'].std()))\n",
        "print(\"Ararage distance: \" + str(train['distance'].mean()) + \" miles\")\n",
        "print(\"Standard deviation distance: \" + str(train['distance'].std()) + \" miles\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KB5A0x0iPBkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F3ZtZtgCt87",
        "colab_type": "text"
      },
      "source": [
        "Visualization of the data <br>\n",
        "\n",
        "The following things were noticed (while using 500k datapoints):\n",
        "*   The minimal fare_amount is negative. As this does not seem to be realistic I will drop them from the dataset.\n",
        "*   Some of the minimum and maximum longitude/lattitude coordinates are way off. These  will also be remove from the dataset. (bounding box will be defined)\n",
        "*   The average fare_amount is about 9.79 USD with a standard deviation of 7.48 USD. When building a predictive model we want to be better than 7.48 USD.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-Wu8kZoB-0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train[train.fare_amount>=0]\n",
        "train = train[(train['distance'] < 30) & (train['distance'] >=0 )]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7Bp_uZoGIqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fare_amount = train['fare_amount'].to_array()\n",
        "passenger_count = train['passenger_count'].to_array()\n",
        "distance = train['distance'].to_array()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JcWhshbET0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.kdeplot(fare_amount).set_title(\"Verteilung des Fahrpreises\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQuUhTOR_xj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "sns.kdeplot(distance).set_title(\"Distanz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctVL7b6XQr6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check max latitude und max longitude of test data\n",
        "print(\"Max lat pickup: \" + str(test['pickup_latitude'].max()))\n",
        "print(\"Max lat dropoff: \" + str(test['dropoff_latitude'].max()))\n",
        "print(\"Max lon pickup: \" + str(test['pickup_longitude'].max()))\n",
        "print(\"Max lon dropoff: \" + str(test['dropoff_longitude'].max()))\n",
        "print(\"\")\n",
        "print(\"Min lat pickup: \" + str(test['pickup_latitude'].min()))\n",
        "print(\"Min lat dropoff: \" + str(test['dropoff_latitude'].min()))\n",
        "print(\"Min lon pickup: \" + str(test['pickup_longitude'].min()))\n",
        "print(\"Min lon dropoff: \" + str(test['dropoff_longitude'].min()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3p3pPHX4Hada",
        "colab_type": "text"
      },
      "source": [
        "Bounding Box New York\n",
        "<table>\n",
        "  <tr>\n",
        "    <th></th>\n",
        "    <th>Dropoff</th>\n",
        "    <th>Pickup</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>Max Long</td>\n",
        "    <td>-72.99096</td>\n",
        "    <td>-72.986534</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "    <td>Max Lat</td>\n",
        "    <td>41.696682</td>\n",
        "    <td>41.709553</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "    <td>Min Long</td>\n",
        "    <td>-74.26323</td>\n",
        "    <td>-74.25219</td>\n",
        "    </tr>\n",
        "   <tr>\n",
        "    <td>Min Lat</td>\n",
        "    <td>40.568974</td>\n",
        "    <td>40.57314</td>\n",
        "   </tr>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMZUYAcDVO1x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nu3O1o0HkkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parts of train data are too far away, so they can be dropped\n",
        "train = train[(train['pickup_longitude'] > -74.25) & (train['pickup_longitude'] < -72.98)]\n",
        "train = train[(train['pickup_latitude'] > 40.57) & (train['pickup_latitude'] < 41.70)]\n",
        "train = train[(train['dropoff_longitude'] < -72.99) & (train['dropoff_longitude'] > -74.26)]\n",
        "train = train[(train['dropoff_latitude'] > 40.56) & (train['dropoff_latitude'] < 41.69)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lh8BCPIjGDkx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropoff_longitude = train['dropoff_longitude'].to_array()\n",
        "dropoff_latitude = train['dropoff_latitude'].to_array()\n",
        "\n",
        "city_long_border = (-74.03, -73.75)\n",
        "city_lat_border = (40.63, 40.85)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(dropoff_longitude, dropoff_latitude,\n",
        "                color='green', \n",
        "                s=.02, alpha=.6)\n",
        "plt.title(\"Dropoffs\")\n",
        "\n",
        "plt.ylim(city_lat_border)\n",
        "plt.xlim(city_long_border)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZqQoFPuGrYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unnecessary_columns=['pickup_datetime','dropoff_latitude','pickup_latitude','dropoff_longitude','pickup_longitude']\n",
        "train=train.drop(unnecessary_columns,axis=1)\n",
        "test=test.drop(unnecessary_columns,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9cNfz9ITCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNd_cXuNg3yL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASbJyvwrLXEA",
        "colab_type": "text"
      },
      "source": [
        "# 4. Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdDCPESrIYfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=train.drop(['fare_amount'],axis=1)\n",
        "y=train['fare_amount']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
        "print(\"Number of records in training data \",X_train.shape[0])\n",
        "print(\"Number of records in validation data \",X_test.shape[0])\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oVWER31Ikbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lm = LinearRegression(fit_intercept = True, normalize = False,\n",
        "                      algorithm = \"eig\")\n",
        "lm.fit(X_train,y_train)\n",
        "y_pred=lm.predict(X_test)\n",
        "lm_rmse = r2_score(y_pred, y_test)\n",
        "print(\"RMSE for Linear Regression is \",lm_rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqMel8pKIpGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=lm.predict(test)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L85j0kDWI2fH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdf_submission = submission\n",
        "gdf_submission['fare_amount']= y_pred\n",
        "\n",
        "gdf_submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6rpJtIjKPQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdf_submission.to_csv(env_submission_path+'submission_LinearReg.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8q2_b90LUju",
        "colab_type": "text"
      },
      "source": [
        "# 5. Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSSWCb9xPv4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=train.drop(['fare_amount'],axis=1)\n",
        "y=train['fare_amount']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
        "print(\"Number of records in training data \",X_train.shape[0])\n",
        "print(\"Number of records in validation data \",X_test.shape[0])\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jusciUoQP0_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params_ridge = {\n",
        "    \"alpha\": loguniform(1e-5, 1e0), # default 1.0\n",
        "    \"solver\": ['eig', 'cd'], \n",
        "}\n",
        "ridge = Ridge()\n",
        "clf = RandomizedSearchCV(ridge, params_ridge, random_state=1, n_iter=100, cv=5, verbose=0, n_jobs=1)\n",
        "best_model = clf.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wUP1Kc9P71y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_model.best_estimator_.get_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVSS1oaeP-hk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ridge_params = {\n",
        " 'alpha': 0.240960447726532,\n",
        " 'fit_intercept': True,\n",
        " 'normalize': False,\n",
        " 'solver': 'eig'\n",
        "}\n",
        "\n",
        "ridge = Ridge(**ridge_params)\n",
        "result_ridge = ridge.fit(X_train,y_train)\n",
        "\n",
        "y_pred = result_ridge.predict(X_test)\n",
        "ridge_rmse = r2_score(y_pred, y_test)\n",
        "print(\"RMSE for Ridge_rmse Regression is \", ridge_rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiacUjg6QDfu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ridge_pred = result_ridge.predict(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO3y0SH9QKXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdf_submission = submission\n",
        "gdf_submission['fare_amount']= ridge_pred\n",
        "\n",
        "gdf_submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9ZhuMwuQURQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdf_submission.to_csv(env_submission_path+'submission_RidReg.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhmGe2pIH8bs",
        "colab_type": "text"
      },
      "source": [
        "# 6. K-Nearest Neighbors Regression\n",
        "\n",
        "https://github.com/rapidsai/cuml/blob/branch-0.13/notebooks/kneighbors_regressor_demo.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlIw0FgjaKgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## params\n",
        "n_neighbors=4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dt2ZS-EZXmAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=train.drop(['fare_amount'],axis=1)\n",
        "y=train['fare_amount']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
        "print(\"Number of records in training data \",X_train.shape[0])\n",
        "print(\"Number of records in validation data \",X_test.shape[0])\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmdzooShH-MM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## inspiration: https://www.kaggle.com/cdeotte/rapids-knn-30-seconds-0-938/notebook\n",
        "\n",
        "%%time\n",
        "knn_cuml = cumlKNR(n_neighbors=n_neighbors)\n",
        "knn_cuml.fit(X_train, y_train)\n",
        "\n",
        "cuml_result = knn_cuml.predict(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjWTGwu_aqNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#y_pred=knn_cuml.predict(X_test)\n",
        "\n",
        "y_pred = knn_cuml.predict(X_test)\n",
        "knn_cuml_rmse = cuml.metrics.regression.r2_score(y_pred, y_test)\n",
        "print(\"RMSE for K-Nearest Neighbor is \",knn_cuml_rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES6Gfl_GggKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzP6K_03ZYyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdf_submission = submission\n",
        "gdf_submission['fare_amount']= cuml_result\n",
        "\n",
        "gdf_submission.head()\n",
        "\n",
        "gdf_submission.to_csv(env_submission_path+'submission_KNearest.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0nLQZe2zzv_",
        "colab_type": "text"
      },
      "source": [
        "# Random Forest GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTlFRIbi1hly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## params\n",
        "n_estimators=10\n",
        "n_jobs=-1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHSZ7-CFz3Xv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=train.drop(['fare_amount'],axis=1)\n",
        "y=train['fare_amount']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
        "print(\"Number of records in training data \",X_train.shape[0])\n",
        "print(\"Number of records in validation data \",X_test.shape[0])\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aJAo-cM0F3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "rf_cuml = cuRF(n_estimators=n_estimators)\n",
        "rf_cuml.fit(X_train, y_train)\n",
        "\n",
        "cuRF_result = rf_cuml.predict(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JopZ4B2P1vh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = rf_cuml.predict(X_test)\n",
        "rf_cuml_rmse = cuml.metrics.regression.r2_score(y_pred, y_test)\n",
        "print(\"RMSE for Random Forest is \",rf_cuml_rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0tAnJJv4T-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdf_submission = submission\n",
        "gdf_submission['fare_amount']= cuRF_result\n",
        "\n",
        "gdf_submission.head()\n",
        "\n",
        "gdf_submission.to_csv(env_submission_path+'submission_RandomForest.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiCY_q1uPEyD",
        "colab_type": "text"
      },
      "source": [
        "# XG Boost model\n",
        "\n",
        "- https://www.kaggle.com/sandeepkumar121995/eda-data-cleaning-xg-boost\n",
        "- https://www.kaggle.com/gunbl4d3/xgboost-ing-taxi-fares\n",
        "- https://www.kaggle.com/aerdem4/m5-lofo-importance-on-gpu-via-rapids-xgboost\n",
        "- https://www.kaggle.com/xhlulu/ieee-fraud-xgboost-with-gpu-fit-in-40s\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCWFrhxye0Aw",
        "colab_type": "text"
      },
      "source": [
        "Running into several problems with XG Boost. Python Kernel stops witout error message \t\n",
        "- what(): parallel_for failed: cudaErrorNoKernelImageForDevice: no kernel image is available for execution on the device\n",
        "- https://www.kaggle.com/c/otto-group-product-classification-challenge/discussion/13308\n",
        "- https://github.com/CannyLab/tsne-cuda/issues/18\n",
        "\n",
        "Hypothesis: There could be an error when loading a cudf dataset in XGBoost. Seems to not happen when using pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfzVFTriPIEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "    'max_depth': 7,\n",
        "    'gamma' :0,\n",
        "    'eta':.03, \n",
        "    'subsample': 1,\n",
        "    'colsample_bytree': 0.9, \n",
        "    'objective':'reg:linear',\n",
        "    'eval_metric':'rmse',\n",
        "    'silent': 0\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e56ryuTPMGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "63fb5bc3-bda1-47f3-caaf-bdf505b37d66"
      },
      "source": [
        "X=train.drop(['fare_amount'],axis=1)\n",
        "y=train['fare_amount']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
        "print(\"Number of records in training data \",X_train.shape[0])\n",
        "print(\"Number of records in validation data \",X_test.shape[0])\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fed8e555a237>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fare_amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fare_amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of records in training data \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpLZNVFIPH5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def XGBmodel(X_train,X_test,y_train,y_test,params):\n",
        "    matrix_train = xgb.DMatrix(X_train,label=y_train)\n",
        "    matrix_test = xgb.DMatrix(X_test,label=y_test)\n",
        "    model=xgb.train(params=params,\n",
        "                    dtrain=matrix_train,num_boost_round=5000, \n",
        "                    early_stopping_rounds=10,evals=[(matrix_test,'test')])\n",
        "    return model\n",
        "\n",
        "XGB_model = XGBmodel(X_train,X_test,y_train,y_test,params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK07JiG4PH0w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "fb56ff71-e93b-456e-9f16-95ae74fc2574"
      },
      "source": [
        "xgb_prediction = XGB_model.predict(xgb.DMatrix(test), ntree_limit = XGB_model.best_ntree_limit).tolist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-43025dcdd3c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGB_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXGB_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_ntree_limit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'XGB_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoAa0Oc8Pu4K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = XGB_model.predict(xgb.DMatrix(X_test))\n",
        "XGB_rmse = cuml.metrics.regression.r2_score(y_pred, y_test)\n",
        "print(\"RMSE for Random Forest is \",XGB_rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYIYJvOpP3Py",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "8007c7c6-7c20-4847-9030-1cbc91891c13"
      },
      "source": [
        "xgb_submission = submission\n",
        "xgb_submission['fare_amount']= xgb_prediction\n",
        "\n",
        "xgb_submission.head()\n",
        "\n",
        "xgb_submission.to_csv(env_submission_path+'submission_XGB.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7e99e0fd1112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmission\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mxgb_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fare_amount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mxgb_prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mxgb_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'submission' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXgn5i-9r2Ih",
        "colab_type": "text"
      },
      "source": [
        "# LGBM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awLaNNrur6tD",
        "colab_type": "text"
      },
      "source": [
        "- https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc\n",
        "\n",
        "- https://www.kaggle.com/nicapotato/taxi-rides-time-analysis-and-oof-lgbm\n",
        "\n",
        "- https://www.kaggle.com/dsaichand3/lgbm-gpu\n",
        "\n",
        "- https://www.kaggle.com/aerdem4/rapids-svm-on-trends-neuroimaging\n",
        "\n",
        "\n",
        "Compared CPU vs GPU:\n",
        "- https://www.kaggle.com/ishivinal/sklearn-rapids-pandas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br4cxQ_dhhOd",
        "colab_type": "text"
      },
      "source": [
        "## Setup LGBM with GPU Support\n",
        "\n",
        "How to setup LGBM GPU Beta:\n",
        "- https://www.kaggle.com/vinhnguyen/gpu-acceleration-for-lightgbm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCEtHPjI3L68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "b5bcaca6-3415-4c52-d503-7321b454821e"
      },
      "source": [
        "!rm -r /opt/conda/lib/python3.6/site-packages/lightgbm\n",
        "!git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "!apt-get install -y -qq libboost-all-dev"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/opt/conda/lib/python3.6/site-packages/lightgbm': No such file or directory\n",
            "Cloning into 'LightGBM'...\n",
            "remote: Enumerating objects: 47, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 19367 (delta 13), reused 4 (delta 0), pack-reused 19320\n",
            "Receiving objects: 100% (19367/19367), 15.65 MiB | 11.91 MiB/s, done.\n",
            "Resolving deltas: 100% (14124/14124), done.\n",
            "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'compute'\n",
            "Cloning into '/content/LightGBM/compute'...\n",
            "remote: Enumerating objects: 21728, done.        \n",
            "remote: Total 21728 (delta 0), reused 0 (delta 0), pack-reused 21728        \n",
            "Receiving objects: 100% (21728/21728), 8.51 MiB | 1.49 MiB/s, done.\n",
            "Resolving deltas: 100% (17565/17565), done.\n",
            "Submodule path 'compute': checked out '36c89134d4013b2e5e45bc55656a18bd6141995a'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55cYhd8bfvff",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2da3c70c-aa6d-4379-e3b4-177dbd01c747"
      },
      "source": [
        "%%bash\n",
        "cd LightGBM\n",
        "rm -r build\n",
        "mkdir build\n",
        "cd build\n",
        "cmake -DUSE_GPU=1 -DOpenCL_LIBRARY=/usr/local/cuda/lib64/libOpenCL.so -DOpenCL_INCLUDE_DIR=/usr/local/cuda/include/ ..\n",
        "make -j$(nproc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- Looking for CL_VERSION_2_2\n",
            "-- Looking for CL_VERSION_2_2 - not found\n",
            "-- Looking for CL_VERSION_2_1\n",
            "-- Looking for CL_VERSION_2_1 - not found\n",
            "-- Looking for CL_VERSION_2_0\n",
            "-- Looking for CL_VERSION_2_0 - not found\n",
            "-- Looking for CL_VERSION_1_2\n",
            "-- Looking for CL_VERSION_1_2 - found\n",
            "-- Found OpenCL: /usr/local/cuda/lib64/libOpenCL.so (found version \"1.2\") \n",
            "-- OpenCL include directory: /usr/local/cuda/include\n",
            "-- Found Boost 1.70.0 at /usr/local/lib/cmake/Boost-1.70.0\n",
            "--   Requested configuration: QUIET REQUIRED COMPONENTS filesystem;system\n",
            "-- Found boost_headers 1.70.0 at /usr/local/lib/cmake/boost_headers-1.70.0\n",
            "-- Found boost_filesystem 1.70.0 at /usr/local/lib/cmake/boost_filesystem-1.70.0\n",
            "--   libboost_filesystem.a\n",
            "-- Adding boost_filesystem dependencies: headers\n",
            "-- Found boost_system 1.70.0 at /usr/local/lib/cmake/boost_system-1.70.0\n",
            "--   libboost_system.a\n",
            "-- Adding boost_system dependencies: headers\n",
            "-- Boost 1.56.0 found.\n",
            "-- Found Boost components:\n",
            "   filesystem;system\n",
            "-- Performing Test MM_PREFETCH\n",
            "-- Performing Test MM_PREFETCH - Success\n",
            "-- Using _mm_prefetch\n",
            "-- Performing Test MM_MALLOC\n",
            "-- Performing Test MM_MALLOC - Success\n",
            "-- Using _mm_malloc\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/LightGBM/build\n",
            "Scanning dependencies of target lightgbm\n",
            "Scanning dependencies of target _lightgbm\n",
            "[  1%] Building CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\n",
            "[  3%] Building CXX object CMakeFiles/_lightgbm.dir/src/application/application.cpp.o\n",
            "[  4%] Building CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\n",
            "[  6%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\n",
            "[  7%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\n",
            "[  9%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\n",
            "[ 10%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\n",
            "[ 12%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\n",
            "[ 14%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\n",
            "[ 15%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\n",
            "[ 17%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\n",
            "[ 18%] Building CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\n",
            "[ 20%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\n",
            "[ 21%] Building CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\n",
            "[ 23%] Building CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\n",
            "[ 25%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\n",
            "[ 26%] Building CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\n",
            "[ 28%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\n",
            "[ 29%] Building CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\n",
            "[ 31%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\n",
            "[ 32%] Building CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\n",
            "[ 34%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\n",
            "[ 35%] Building CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\n",
            "[ 37%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\n",
            "[ 39%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\n",
            "[ 40%] Building CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\n",
            "[ 42%] Building CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\n",
            "[ 43%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\n",
            "[ 45%] Building CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\n",
            "[ 46%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\n",
            "[ 48%] Building CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\n",
            "[ 50%] Building CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\n",
            "[ 51%] Building CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\n",
            "[ 53%] Building CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\n",
            "[ 54%] Building CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\n",
            "[ 56%] Building CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\n",
            "[ 57%] Building CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\n",
            "[ 59%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\n",
            "[ 60%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\n",
            "[ 62%] Building CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\n",
            "[ 64%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\n",
            "[ 65%] Building CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\n",
            "[ 67%] Building CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\n",
            "[ 68%] Building CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\n",
            "[ 70%] Building CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\n",
            "[ 71%] Building CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\n",
            "[ 73%] Building CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\n",
            "[ 75%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\n",
            "[ 76%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\n",
            "[ 78%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\n",
            "[ 79%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\n",
            "[ 81%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\n",
            "[ 82%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\n",
            "[ 84%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\n",
            "[ 85%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\n",
            "[ 87%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\n",
            "[ 89%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\n",
            "[ 90%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\n",
            "[ 92%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\n",
            "[ 93%] Building CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\n",
            "[ 95%] Building CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\n",
            "[ 96%] Linking CXX executable ../lightgbm\n",
            "[ 98%] Building CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\n",
            "CMakeFiles/lightgbm.dir/build.make:534: recipe for target '../lightgbm' failed\n",
            "CMakeFiles/Makefile2:109: recipe for target 'CMakeFiles/lightgbm.dir/all' failed\n",
            "[100%] Linking CXX shared library ../lib_lightgbm.so\n",
            "[100%] Built target _lightgbm\n",
            "Makefile:129: recipe for target 'all' failed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'build': No such file or directory\n",
            "CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o: In function `boost::compute::detail::program_binary_path(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, bool)':\n",
            "gpu_tree_learner.cpp:(.text._ZN5boost7compute6detail19program_binary_pathERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb[_ZN5boost7compute6detail19program_binary_pathERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb]+0x1e5): undefined reference to `boost::filesystem::detail::status(boost::filesystem::path const&, boost::system::error_code*)'\n",
            "gpu_tree_learner.cpp:(.text._ZN5boost7compute6detail19program_binary_pathERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb[_ZN5boost7compute6detail19program_binary_pathERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEb]+0x233): undefined reference to `boost::filesystem::detail::create_directories(boost::filesystem::path const&, boost::system::error_code*)'\n",
            "CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o: In function `boost::compute::detail::parameter_cache_path[abi:cxx11](bool)':\n",
            "gpu_tree_learner.cpp:(.text._ZN5boost7compute6detail20parameter_cache_pathB5cxx11Eb[_ZN5boost7compute6detail20parameter_cache_pathB5cxx11Eb]+0x70): undefined reference to `boost::filesystem::detail::status(boost::filesystem::path const&, boost::system::error_code*)'\n",
            "gpu_tree_learner.cpp:(.text._ZN5boost7compute6detail20parameter_cache_pathB5cxx11Eb[_ZN5boost7compute6detail20parameter_cache_pathB5cxx11Eb]+0xb4): undefined reference to `boost::filesystem::detail::create_directories(boost::filesystem::path const&, boost::system::error_code*)'\n",
            "CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o: In function `boost::detail::sp_if_not_array<boost::compute::detail::parameter_cache>::type boost::make_shared<boost::compute::detail::parameter_cache, boost::compute::device const&>(boost::compute::device const&)':\n",
            "gpu_tree_learner.cpp:(.text._ZN5boost11make_sharedINS_7compute6detail15parameter_cacheEJRKNS1_6deviceEEEENS_6detail15sp_if_not_arrayIT_E4typeEDpOT0_[_ZN5boost11make_sharedINS_7compute6detail15parameter_cacheEJRKNS1_6deviceEEEENS_6detail15sp_if_not_arrayIT_E4typeEDpOT0_]+0x127): undefined reference to `boost::filesystem::detail::status(boost::filesystem::path const&, boost::system::error_code*)'\n",
            "collect2: error: ld returned 1 exit status\n",
            "make[2]: *** [../lightgbm] Error 1\n",
            "make[1]: *** [CMakeFiles/lightgbm.dir/all] Error 2\n",
            "make[1]: *** Waiting for unfinished jobs....\n",
            "make: *** [all] Error 2\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAb6mTwwqps-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c229c029-3978-4191-8d07-07eaa99f8cb0"
      },
      "source": [
        "!cd LightGBM/python-package/;python3 setup.py install --precompile\n",
        "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
        "!rm -r LightGBM"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running install\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/lightgbm\n",
            "copying lightgbm/compat.py -> build/lib/lightgbm\n",
            "copying lightgbm/callback.py -> build/lib/lightgbm\n",
            "copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
            "copying lightgbm/plotting.py -> build/lib/lightgbm\n",
            "copying lightgbm/__init__.py -> build/lib/lightgbm\n",
            "copying lightgbm/basic.py -> build/lib/lightgbm\n",
            "copying lightgbm/libpath.py -> build/lib/lightgbm\n",
            "copying lightgbm/engine.py -> build/lib/lightgbm\n",
            "running egg_info\n",
            "creating lightgbm.egg-info\n",
            "writing lightgbm.egg-info/PKG-INFO\n",
            "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
            "writing requirements to lightgbm.egg-info/requires.txt\n",
            "writing top-level names to lightgbm.egg-info/top_level.txt\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "reading manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "no previously-included directories found matching 'build'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching '*.txt'\n",
            "warning: no files found matching '*.so' under directory 'lightgbm'\n",
            "warning: no files found matching '*.txt' under directory 'compile'\n",
            "warning: no files found matching '*.so' under directory 'compile'\n",
            "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
            "warning: no files found matching '*' under directory 'compile/compute'\n",
            "warning: no files found matching '*' under directory 'compile/include'\n",
            "warning: no files found matching '*' under directory 'compile/src'\n",
            "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
            "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
            "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
            "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
            "running install_lib\n",
            "creating /usr/local/lib/python3.6/site-packages/lightgbm\n",
            "copying build/lib/lightgbm/compat.py -> /usr/local/lib/python3.6/site-packages/lightgbm\n",
            "copying build/lib/lightgbm/callback.py -> /usr/local/lib/python3.6/site-packages/lightgbm\n",
            "copying build/lib/lightgbm/sklearn.py -> /usr/local/lib/python3.6/site-packages/lightgbm\n",
            "copying build/lib/lightgbm/plotting.py -> /usr/local/lib/python3.6/site-packages/lightgbm\n",
            "copying build/lib/lightgbm/__init__.py -> /usr/local/lib/python3.6/site-packages/lightgbm\n",
            "copying build/lib/lightgbm/basic.py -> /usr/local/lib/python3.6/site-packages/lightgbm\n",
            "copying build/lib/lightgbm/VERSION.txt -> /usr/local/lib/python3.6/site-packages/lightgbm\n",
            "copying build/lib/lightgbm/libpath.py -> /usr/local/lib/python3.6/site-packages/lightgbm\n",
            "copying build/lib/lightgbm/engine.py -> /usr/local/lib/python3.6/site-packages/lightgbm\n",
            "INFO:LightGBM:Installing lib_lightgbm from: ['../lib_lightgbm.so']\n",
            "copying ../lib_lightgbm.so -> /usr/local/lib/python3.6/site-packages/lightgbm\n",
            "byte-compiling /usr/local/lib/python3.6/site-packages/lightgbm/compat.py to compat.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/site-packages/lightgbm/callback.py to callback.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/site-packages/lightgbm/sklearn.py to sklearn.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/site-packages/lightgbm/plotting.py to plotting.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/site-packages/lightgbm/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/site-packages/lightgbm/basic.py to basic.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/site-packages/lightgbm/libpath.py to libpath.cpython-36.pyc\n",
            "byte-compiling /usr/local/lib/python3.6/site-packages/lightgbm/engine.py to engine.cpython-36.pyc\n",
            "running install_egg_info\n",
            "Copying lightgbm.egg-info to /usr/local/lib/python3.6/site-packages/lightgbm-3.0.0.99-py3.6.egg-info\n",
            "running install_scripts\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVlid4GMsy2W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "4e14a227-78e7-43f5-ba42-d315ef68776c"
      },
      "source": [
        "import lightgbm as lgbm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-e129fb0ec361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/lightgbm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from .callback import (early_stopping, print_evaluation, record_evaluation,\n\u001b[1;32m     10\u001b[0m                        reset_parameter)\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCFUNCTYPE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /usr/local/lib/python3.6/site-packages/lightgbm/lib_lightgbm.so: undefined symbol: _ZN5boost10filesystem6detail18create_directoriesERKNS0_4pathEPNS_6system10error_codeE"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS403xD2hqTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Inspiration from https://www.kaggle.com/dsaichand3/lgbm-gpu\n",
        "params = {\n",
        "        'boosting_type':'gbdt',\n",
        "        'objective': 'regression',\n",
        "        'nthread': 4,\n",
        "        'num_leaves': 31,\n",
        "        'learning_rate': 0.15,\n",
        "        'max_depth': -1,\n",
        "        'subsample': 0.8,\n",
        "        'bagging_fraction' : 1,\n",
        "        'max_bin' : 15,\n",
        "        'bagging_freq': 20,\n",
        "        'colsample_bytree': 0.6,\n",
        "        'metric': 'rmse',\n",
        "        'min_split_gain': 0.5,\n",
        "        'min_child_weight': 1,\n",
        "        'min_child_samples': 10,\n",
        "        'scale_pos_weight':1,\n",
        "        'zero_as_missing': True,\n",
        "        'seed':0,\n",
        "        'num_rounds':50000,\n",
        "        'device': 'gpu',\n",
        "        'gpu_platform_id': 0,\n",
        "        'gpu_device_id': 0\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG0yNPRkn7Tn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=train.drop(['fare_amount'],axis=1)\n",
        "y=train['fare_amount']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)\n",
        "print(\"Number of records in training data \",X_train.shape[0])\n",
        "print(\"Number of records in validation data \",X_test.shape[0])\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RIJOuhNoM2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4ihZhGkip44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "train_set = lgbm.Dataset(x_train, y_train, silent=False, categorical_feature=['year','month','day'])\n",
        "valid_set = lgbm.Dataset(x_test, y_test, silent=False, categorical_feature=['year','month','day'])\n",
        "del x_train, y_train, x_test, y_test\n",
        "gc.collect()\n",
        "model = lgbm.train(params, train_set = train_set, num_boost_round=10000, early_stopping_rounds=500, verbose_eval=500, valid_sets=valid_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PAZn171ip1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv(\"/kaggle/input/new-york-city-taxi-fare-prediction/train.csv\", nrows = 25000000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFYM35GRhqNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LGBM_pred = model.predict(test, num_iteration = model.best_iteration)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpiQu9UqtgzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gdf_submission = submission\n",
        "gdf_submission['fare_amount']= LBGM_pred\n",
        "\n",
        "gdf_submission.to_csv(env_submission_path+'submission_LGBM.csv',index=False)\n",
        "\n",
        "gdf_submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz1vk8UNVeAv",
        "colab_type": "text"
      },
      "source": [
        "# 7. Evaluation and Discussion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz0YAjbPVhMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}